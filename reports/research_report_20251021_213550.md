# üìä B√°o C√°o Nghi√™n C·ª©u Agentic AI

**Ng√†y t·∫°o:** 21/10/2025 21:35

**T·ªïng s·ªë papers:** 50

---

## üìã T√≥m T·∫Øt ƒêi·ªÅu H√†nh

B√°o c√°o n√†y t·ªïng h·ª£p 50 b√†i b√°o nghi√™n c·ª©u m·ªõi nh·∫•t v·ªÅ Agentic AI, ph√¢n t√≠ch xu h∆∞·ªõng c√¥ng ngh·ªá v√† ƒë·ªÅ xu·∫•t c√°c h∆∞·ªõng nghi√™n c·ª©u ti·ªÅm nƒÉng.

## üìà Ph√¢n T√≠ch Xu H∆∞·ªõng

### T·ª´ Kh√≥a N·ªïi B·∫≠t

| T·ª´ Kh√≥a | T·∫ßn Su·∫•t |
|---------|----------|
| models | 44 |
| agents | 42 |
| based | 36 |
| model | 33 |
| agent | 32 |
| learning | 32 |
| multi | 30 |
| framework | 28 |
| language | 28 |
| through | 28 |

### C·ª•m T·ª´ Quan Tr·ªçng

| C·ª•m T·ª´ | T·∫ßn Su·∫•t |
|---------|----------|
| large language | 15 |
| language models | 15 |
| multi agent | 14 |
| models llms | 8 |
| reinforcement learning | 7 |
| post training | 7 |
| real world | 6 |
| large scale | 6 |
| ai systems | 6 |
| artificial intelligence | 6 |

### Ph√¢n B·ªë Theo Ch·ªß ƒê·ªÅ

**AI Agents**: 26 papers (52.0%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà

**LLM & Foundation Models**: 11 papers (22.0%) ‚ñà‚ñà‚ñà‚ñà

**Other**: 7 papers (14.0%) ‚ñà‚ñà

**RAG & Knowledge**: 4 papers (8.0%) ‚ñà

**Automation & Tools**: 2 papers (4.0%) 

## üí° ƒê·ªÅ Xu·∫•t √ù T∆∞·ªüng Nghi√™n C·ª©u

### 1. Nghi√™n c·ª©u ·ª©ng d·ª•ng large language trong c√°c h·ªá th·ªëng models

**M√¥ t·∫£:** Xu h∆∞·ªõng m·ªõi n·ªïi v·ªõi 15 mentions

**ƒê·ªô ∆∞u ti√™n:** High

**T·ª´ kh√≥a li√™n quan:** large language, models

### 2. Ph√°t tri·ªÉn framework language models cho agents

**M√¥ t·∫£:** Xu h∆∞·ªõng m·ªõi n·ªïi v·ªõi 15 mentions

**ƒê·ªô ∆∞u ti√™n:** High

**T·ª´ kh√≥a li√™n quan:** language models, agents

### 3. ƒê√°nh gi√° hi·ªáu qu·∫£ c·ªßa multi agent trong b·ªëi c·∫£nh based

**M√¥ t·∫£:** Xu h∆∞·ªõng m·ªõi n·ªïi v·ªõi 14 mentions

**ƒê·ªô ∆∞u ti√™n:** Medium

**T·ª´ kh√≥a li√™n quan:** multi agent, based

### 4. T·ªëi ∆∞u h√≥a models llms s·ª≠ d·ª•ng k·ªπ thu·∫≠t model

**M√¥ t·∫£:** Xu h∆∞·ªõng m·ªõi n·ªïi v·ªõi 8 mentions

**ƒê·ªô ∆∞u ti√™n:** Medium

**T·ª´ kh√≥a li√™n quan:** models llms, model

### 5. K·∫øt h·ª£p reinforcement learning v√† agent ƒë·ªÉ c·∫£i thi·ªán performance

**M√¥ t·∫£:** Xu h∆∞·ªõng m·ªõi n·ªïi v·ªõi 7 mentions

**ƒê·ªô ∆∞u ti√™n:** Medium

**T·ª´ kh√≥a li√™n quan:** reinforcement learning, agent

### 6. Kh·∫£o s√°t to√†n di·ªán v·ªÅ AI Agents trong Agentic AI

**M√¥ t·∫£:** C√≥ 26 papers g·∫ßn ƒë√¢y v·ªÅ ch·ªß ƒë·ªÅ n√†y, c·∫ßn t·ªïng h·ª£p h·ªá th·ªëng

**ƒê·ªô ∆∞u ti√™n:** High

**T·ª´ kh√≥a li√™n quan:** ai agents

### 7. Kh·∫£o s√°t to√†n di·ªán v·ªÅ LLM & Foundation Models trong Agentic AI

**M√¥ t·∫£:** C√≥ 11 papers g·∫ßn ƒë√¢y v·ªÅ ch·ªß ƒë·ªÅ n√†y, c·∫ßn t·ªïng h·ª£p h·ªá th·ªëng

**ƒê·ªô ∆∞u ti√™n:** Medium

**T·ª´ kh√≥a li√™n quan:** llm & foundation models

### 8. Kh·∫£o s√°t to√†n di·ªán v·ªÅ Other trong Agentic AI

**M√¥ t·∫£:** C√≥ 7 papers g·∫ßn ƒë√¢y v·ªÅ ch·ªß ƒë·ªÅ n√†y, c·∫ßn t·ªïng h·ª£p h·ªá th·ªëng

**ƒê·ªô ∆∞u ti√™n:** Medium

**T·ª´ kh√≥a li√™n quan:** other

## üìö C√°c B√†i B√°o M·ªõi Nh·∫•t

### 1. Enterprise Deep Research: Steerable Multi-Agent Deep Research for Enterprise Analytics

**T√°c gi·∫£:** Akshara Prabhakar, Roshan Ram, Zixiang Chen et al.

**Ng√†y xu·∫•t b·∫£n:** 2025-10-20

**Ngu·ªìn:** arxiv

**T√≥m t·∫Øt:** As information grows exponentially, enterprises face increasing pressure to transform unstructured data into coherent, actionable insights. We present Enterprise Deep Research (EDR), a multi-agent system that integrates (1) a Master Planning Agent for adaptive query decomposition, (2) four specialized search agents (General, Academic, GitHub, LinkedIn), (3) an extensible MCP-based tool ecosystem supporting NL2SQL, file analysis, and enterprise workflows, (4) a Visualization Agent for data-driven insights, and (5) a reflection mechanism that detects knowledge gaps and updates research direction with optional human-in-the-loop steering guidance. On open-ended benchmarks including DeepResearch Bench and DeepConsult, EDR outperforms state-of-the-art agentic systems without any human steering.

**Link:** [http://arxiv.org/pdf/2510.17797v1](http://arxiv.org/pdf/2510.17797v1)

---

### 2. Executable Knowledge Graphs for Replicating AI Research

**T√°c gi·∫£:** Yujie Luo, Zhuoyun Yu, Xuehai Wang et al.

**Ng√†y xu·∫•t b·∫£n:** 2025-10-20

**Ngu·ªìn:** arxiv

**T√≥m t·∫Øt:** Replicating AI research is a crucial yet challenging task for large language model (LLM) agents. Existing approaches often struggle to generate executable code, primarily due to insufficient background knowledge and the limitations of retrieval-augmented generation (RAG) methods, which fail to capture latent technical details hidden in referenced papers. When integrated into three agent frameworks with two different LLMs, xKG shows substantial performance gains (10.9% with o3-mini) on PaperBench, demonstrating its effectiveness as a general and extensible solution for automated AI research replication.

**Link:** [http://arxiv.org/pdf/2510.17795v1](http://arxiv.org/pdf/2510.17795v1)

---

### 3. UltraCUA: A Foundation Model for Computer Use Agents with Hybrid Action

**T√°c gi·∫£:** Yuhao Yang, Zhen Yang, Zi-Yi Dou et al.

**Ng√†y xu·∫•t b·∫£n:** 2025-10-20

**Ngu·ªìn:** arxiv

**T√≥m t·∫Øt:** Multimodal agents for computer use rely exclusively on primitive actions (click, type, scroll) that require accurate visual grounding and lengthy execution chains, leading to cascading failures and performance bottlenecks. To achieve this, our approach comprises four key components: (1) an automated pipeline that scales programmatic tools from software documentation, open-source repositories, and code generation; (2) a synthetic data engine producing over 17,000 verifiable tasks spanning real-world computer-use scenarios; (3) a large-scale high-quality hybrid action trajectory collection with both low-level GUI actions and high-level programmatic tool calls; and (4) a two-stage training pipeline combining supervised fine-tuning with online reinforcement learning, enabling strategic alternation between low-level and high-level actions. We present UltraCUA, a foundation model that bridges this gap through hybrid action -- seamlessly integrating GUI primitives with high-level programmatic tool calls.

**Link:** [http://arxiv.org/pdf/2510.17790v1](http://arxiv.org/pdf/2510.17790v1)

---

### 4. Mapping Post-Training Forgetting in Language Models at Scale

**T√°c gi·∫£:** Jackson Harmon, Andreas Hochlehnert, Matthias Bethge et al.

**Ng√†y xu·∫•t b·∫£n:** 2025-10-20

**Ngu·ªìn:** arxiv

**T√≥m t·∫Øt:** Scaled post-training now drives many of the largest capability gains in language models (LMs), yet its effect on pretrained knowledge remains poorly understood. Our large-scale analysis shows that: (1) Domain-continual pretraining induces moderate forgetting with low-to-moderate backward transfer; (2) RL/SFT post-training applied to base models and Instruction tuning yields moderate-to-large backward transfer on math and logic with overall low-to-moderate forgetting; (3) Applying RL/SFT to instruction-tuned models is sensitive on data scale: at small scales, both forgetting and backward transfer are small; at larger scales, effects are mixed and warrant further study with better controls; (4) Model merging does not reliably mitigate forgetting. Overall, our framework offers a practical yardstick for mapping how post-training alters pretrained knowledge at scale -- enabling progress towards generally capable AI systems..

**Link:** [http://arxiv.org/pdf/2510.17776v1](http://arxiv.org/pdf/2510.17776v1)

---

### 5. Data-driven Communication and Control Design for Distributed Frequency Regulation with Black-box Inverters

**T√°c gi·∫£:** Michael Nestor, Jiaxin Wang, Ning Zhang et al.

**Ng√†y xu·∫•t b·∫£n:** 2025-10-20

**Ngu·ªìn:** arxiv

**T√≥m t·∫Øt:** The increasing penetration of inverter-based resources into the power grid, with often only black-box models available, challenges long-standing frequency control methods. To enable a trade off between communication network requirements and control performance, we present a framework to guide communication topology design for secondary frequency regulation. Following design of the inter-agent information exchange scheme, we design a controller that is structured according to the communication topology with a closed-loop stability guarantee.

**Link:** [http://arxiv.org/pdf/2510.17769v1](http://arxiv.org/pdf/2510.17769v1)

---

### 6. Phantom scalar field with arbitrary potential: accelerating scaling attractors

**T√°c gi·∫£:** Sudip Halder, Supriya Pan, Paulo M. S√° et al.

**Ng√†y xu·∫•t b·∫£n:** 2025-10-20

**Ngu·ªìn:** arxiv

**T√≥m t·∫Øt:** In this article, we investigate the dynamics of a phantom scalar field with an arbitrary potential, focusing on accelerating scaling solutions of cosmological relevance. Although there is a limitation to these scaling solutions $-$ specifically, the current stage of accelerated expansion is not preceded by a long enough matter-dominated era $-$ our results show that the existence of a direct coupling between phantom dark energy and dark matter yields great potential for addressing the cosmic coincidence problem.. We show that the uncoupled phantom cosmological model cannot accommodate any accelerated scaling solution, while such solutions do exist in the coupled scenario, for both constant and variable dissipation coefficients.

**Link:** [http://arxiv.org/pdf/2510.17765v1](http://arxiv.org/pdf/2510.17765v1)

---

### 7. Evaluating Medical LLMs by Levels of Autonomy: A Survey Moving from Benchmarks to Applications

**T√°c gi·∫£:** Xiao Ye, Jacob Dineen, Zhaonan Li et al.

**Ng√†y xu·∫•t b·∫£n:** 2025-10-20

**Ngu·ªìn:** arxiv

**T√≥m t·∫Øt:** Medical Large language models achieve strong scores on standard benchmarks; however, the transfer of those results to safe and reliable performance in clinical workflows remains a challenge. This survey reframes evaluation through a levels-of-autonomy lens (L0-L3), spanning informational tools, information transformation and aggregation, decision support, and supervised agents. This motivates a level-conditioned blueprint for selecting metrics, assembling evidence, and reporting claims, alongside directions that link evaluation to oversight.

**Link:** [http://arxiv.org/pdf/2510.17764v1](http://arxiv.org/pdf/2510.17764v1)

---

### 8. Human-AI Interactions: Cognitive, Behavioral, and Emotional Impacts

**T√°c gi·∫£:** Celeste Riley, Omar Al-Refai, Yadira Colunga Reyes et al.

**Ng√†y xu·∫•t b·∫£n:** 2025-10-20

**Ngu·ªìn:** arxiv

**T√≥m t·∫Øt:** As stories of human-AI interactions continue to be highlighted in the news and research platforms, the challenges are becoming more pronounced, including potential risks of overreliance, cognitive offloading, social and emotional manipulation, and the nuanced degradation of human agency and judgment. This paper aims to underscore the need for responsible and context-aware AI design, highlighting gaps for longitudinal research and grounded evaluation frameworks to balance benefits with emerging human-centric risks.. Observations seem to suggest that while AI can substantially enhance memory, creativity, and engagement, it also introduces risks such as diminished critical thinking, skill erosion, and increased anxiety.

**Link:** [http://arxiv.org/pdf/2510.17753v1](http://arxiv.org/pdf/2510.17753v1)

---

### 9. Rethinking Search: A Study of University Students' Perspectives on Using LLMs and Traditional Search Engines in Academic Problem Solving

**T√°c gi·∫£:** Md. Faiyaz Abdullah Sayeedi, Md. Sadman Haque, Zobaer Ibn Razzaque et al.

**Ng√†y xu·∫•t b·∫£n:** 2025-10-20

**Ngu·ªìn:** arxiv

**T√≥m t·∫Øt:** With the increasing integration of Artificial Intelligence (AI) in academic problem solving, university students frequently alternate between traditional search engines like Google and large language models (LLMs) for information retrieval. In response, we developed a prototype, a chatbot embedded within the search interface, that combines GPT's conversational capabilities with Google's reliability to enhance academic research and reduce cognitive load.. Qualitative insights revealed that students commonly switch between GPT and Google: using Google for credible, multi-source information and GPT for summarization, explanation, and drafting.

**Link:** [http://arxiv.org/pdf/2510.17726v1](http://arxiv.org/pdf/2510.17726v1)

---

### 10. MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues

**T√°c gi·∫£:** Yaning Pan, Zekun Wang, Qianqian Xie et al.

**Ng√†y xu·∫•t b·∫£n:** 2025-10-20

**Ngu·ªìn:** arxiv

**T√≥m t·∫Øt:** The recent development of Multimodal Large Language Models (MLLMs) has significantly advanced AI's ability to understand visual modalities. With MT-Video-Bench, we extensively evaluate various state-of-the-art open-source and closed-source MLLMs, revealing their significant performance discrepancies and limitations in handling multi-turn video dialogues. Specifically, our MT-Video-Bench mainly assesses six core competencies that focus on perceptivity and interactivity, encompassing 987 meticulously curated multi-turn dialogues from diverse domains.

**Link:** [http://arxiv.org/pdf/2510.17722v1](http://arxiv.org/pdf/2510.17722v1)

---

### 11. Discrimination, intelligence artificielle et decisions algorithmiques

**T√°c gi·∫£:** Frederik Zuiderveen Borgesius

**Ng√†y xu·∫•t b·∫£n:** 2025-10-20

**Ngu·ªìn:** arxiv

**T√≥m t·∫Øt:** Artificial intelligence (AI) has a huge impact on our personal lives and also on our democratic society as a whole. Frederik Zuiderveen Borgesius for the Anti-discrimination Department of the Council of Europe, elaborates on the risks of discrimination caused by algorithmic decision-making and other types of artificial intelligence (AI).. While AI offers vast opportunities for the benefit of people, its potential to embed and perpetuate bias and discrimination remains one of the most pressing challenges deriving from its increasing use.

**Link:** [http://arxiv.org/pdf/2510.17711v1](http://arxiv.org/pdf/2510.17711v1)

---

### 12. Towards Mining Effective Pedagogical Strategies from Learner-LLM Educational Dialogues

**T√°c gi·∫£:** Liqun He, Manolis Mavrikis, Mutlu Cukurova

**Ng√†y xu·∫•t b·∫£n:** 2025-10-20

**Ngu·ªìn:** arxiv

**T√≥m t·∫Øt:** Dialogue plays a crucial role in educational settings, yet existing evaluation methods for educational applications of large language models (LLMs) primarily focus on technical performance or learning outcomes, often neglecting attention to learner-LLM interactions. To narrow this gap, this AIED Doctoral Consortium paper presents an ongoing study employing a dialogue analysis approach to identify effective pedagogical strategies from learner-LLM dialogues. The work underscores the need to evaluate LLM-based educational applications by focusing on dialogue dynamics and pedagogical strategies..

**Link:** [http://arxiv.org/pdf/2510.17698v1](http://arxiv.org/pdf/2510.17698v1)

---

### 13. A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning

**T√°c gi·∫£:** Anjie Liu, Jianhong Wang, Samuel Kaski et al.

**Ng√†y xu·∫•t b·∫£n:** 2025-10-20

**Ngu·ªìn:** arxiv

**T√≥m t·∫Øt:** Steering cooperative multi-agent reinforcement learning (MARL) towards desired outcomes is challenging, particularly when the global guidance from a human on the whole multi-agent system is impractical in a large-scale MARL. Since MAIDs can be regarded as a special class of causal diagrams, a composite desired outcome that integrates the primary task goal and an additional desired outcome can be achieved by maximizing the corresponding causal effect through the PSI. Then, we design a new interaction paradigm based on MAIDs, referred to as targeted intervention that is applied to only a single targeted agent, so the problem of global guidance can be mitigated.

**Link:** [http://arxiv.org/pdf/2510.17697v1](http://arxiv.org/pdf/2510.17697v1)

---

### 14. Semantic Joint Source Channel Coding for Distributed Subsurface Imaging in Multi-Agent Systems

**T√°c gi·∫£:** Maximilian H. V. Tillmann, Ban-Sok Shin, Dmitriy Shutin et al.

**Ng√†y xu·∫•t b·∫£n:** 2025-10-20

**Ngu·ªìn:** arxiv

**T√≥m t·∫Øt:** Multi-agent systems (MAS) are a promising solution for autonomous exploration tasks in hazardous or remote environments, such as planetary surveys. Specifically, we investigate the application of semantic joint source-channel coding (JSCC) with over-the-air computation (AirComp) for distributed function computation for the application of cooperative subsurface imaging using the adapt-then-combine full waveform inversion (ATC-FWI) algorithm. This work presents a novel framework that tightly integrates semantic communication into the MAS exploration process, adapting communication strategies to the exploration methodology to improve overall task performance.

**Link:** [http://arxiv.org/pdf/2510.17695v1](http://arxiv.org/pdf/2510.17695v1)

---

### 15. A Mimamsa Inspired Framework For Instruction Sequencing In AI Agents

**T√°c gi·∫£:** Bama Srinivasan

**Ng√†y xu·∫•t b·∫£n:** 2025-10-20

**Ngu·ªìn:** arxiv

**T√≥m t·∫Øt:** This paper presents a formal framework for sequencing instructions in AI agents, inspired by the Indian philosophical system of Mimamsa. The framework formalizes sequencing mechanisms through action object pairs in three distinct ways: direct assertion (Srutikrama) for temporal precedence, purpose driven sequencing (Arthakrama) for functional dependencies, and iterative procedures (Pravrittikrama) for distinguishing between parallel and sequential execution in repetitive tasks. This formal verification enables reliable instruction sequencing, impacting AI applications across areas like task planning and robotics by addressing temporal reasoning and dependency modeling..

**Link:** [http://arxiv.org/pdf/2510.17691v1](http://arxiv.org/pdf/2510.17691v1)

---

### 16. 4DSegStreamer: Streaming 4D Panoptic Segmentation via Dual Threads

**T√°c gi·∫£:** Ling Liu, Jun Tian, Li Yi

**Ng√†y xu·∫•t b·∫£n:** 2025-10-20

**Ngu·ªìn:** arxiv

**T√≥m t·∫Øt:** 4D panoptic segmentation in a streaming setting is critical for highly dynamic environments, such as evacuating dense crowds and autonomous driving in complex scenarios, where real-time, fine-grained perception within a constrained time budget is essential. The inference thread ensures timely prediction for incoming frames by aligning with the latest memory and compensating for ego-motion and dynamic object movements. Comprehensive experiments demonstrate the effectiveness of our approach, particularly in accurately predicting dynamic objects in complex scenes..

**Link:** [http://arxiv.org/pdf/2510.17664v1](http://arxiv.org/pdf/2510.17664v1)

---

### 17. Frugal Federated Learning for Violence Detection: A Comparison of LoRA-Tuned VLMs and Personalized CNNs

**T√°c gi·∫£:** S√©bastien Thuau, Siba Haidar, Ayush Bajracharya et al.

**Ng√†y xu·∫•t b·∫£n:** 2025-10-20

**Ngu·ªìn:** arxiv

**T√≥m t·∫Øt:** We examine frugal federated learning approaches to violence detection by comparing two complementary strategies: (i) zero-shot and federated fine-tuning of vision-language models (VLMs), and (ii) personalized training of a compact 3D convolutional neural network (CNN3D). To our knowledge, this is the first comparative study of LoRA-tuned vision-language models and personalized CNNs for federated violence detection, with an emphasis on energy efficiency and environmental metrics. The resulting framework offers a reproducible baseline for responsible, resource-aware AI in video surveillance, with extensions toward real-time, multimodal, and lifecycle-aware systems..

**Link:** [http://arxiv.org/pdf/2510.17651v1](http://arxiv.org/pdf/2510.17651v1)

---

### 18. CaMiT: A Time-Aware Car Model Dataset for Classification and Generation

**T√°c gi·∫£:** Fr√©d√©ric LIN, Biruk Abere Ambaw, Adrian Popescu et al.

**Ng√†y xu·∫•t b·∫£n:** 2025-10-20

**Ngu·ªìn:** arxiv

**T√≥m t·∫Øt:** AI systems must adapt to evolving visual environments, especially in domains where object appearances change over time. Static pretraining on in-domain data achieves competitive performance with large-scale generalist models while being more resource-efficient, yet accuracy declines when models are tested across years. We evaluate two strategies: time-incremental pretraining, which updates the backbone, and time-incremental classifier learning, which updates only the final layer, both improving temporal robustness.

**Link:** [http://arxiv.org/pdf/2510.17626v1](http://arxiv.org/pdf/2510.17626v1)

---

### 19. ImaGGen: Zero-Shot Generation of Co-Speech Semantic Gestures Grounded in Language and Image Input

**T√°c gi·∫£:** Hendric Voss, Stefan Kopp

**Ng√†y xu·∫•t b·∫£n:** 2025-10-20

**Ngu·ªìn:** arxiv

**T√≥m t·∫Øt:** Human communication combines speech with expressive nonverbal cues such as hand gestures that serve manifold communicative functions. While challenges remain in representing complex shapes, our results highlight the importance of context-aware semantic gestures for creating expressive and collaborative virtual agents or avatars, marking a substantial step forward towards efficient and robust, embodied human-agent interaction. In scenarios where speech alone was ambiguous, gestures generated by our system significantly improved participants' ability to identify object properties, confirming their interpretability and communicative value.

**Link:** [http://arxiv.org/pdf/2510.17617v1](http://arxiv.org/pdf/2510.17617v1)

---

### 20. ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling

**T√°c gi·∫£:** Shuyuan Zhang, Chenhan Jiang, Zuoou Li et al.

**Ng√†y xu·∫•t b·∫£n:** 2025-10-20

**Ngu·ªìn:** arxiv

**T√≥m t·∫Øt:** 3D generation from natural language offers significant potential to reduce expert manual modeling efforts and enhance accessibility to 3D assets. At its core, we propose a Graph-based Procedural Shape (GPS) representation that decomposes complex natural language into a structured graph of sub-tasks, thereby facilitating accurate LLM comprehension and interpretation of spatial relationships and semantic shape details. Qualitative and quantitative experiments demonstrate ShapeCraft's superior performance in generating geometrically accurate and semantically rich 3D assets compared to existing LLM-based agents.

**Link:** [http://arxiv.org/pdf/2510.17603v1](http://arxiv.org/pdf/2510.17603v1)

---

## üìå Ghi Ch√∫

B√°o c√°o n√†y ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông b·ªüi Agentic AI Research System.
D·ªØ li·ªáu ƒë∆∞·ª£c thu th·∫≠p t·ª´ ArXiv v√† Semantic Scholar.

