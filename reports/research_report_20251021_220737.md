#  Báo Cáo Nghiên Cứu Agentic AI

**Ngày tạo:** 21/10/2025 22:07

**Tổng số papers:** 50

---

## Tóm Tắt Điều Hành

Báo cáo này tổng hợp 50 bài báo nghiên cứu mới nhất về Agentic AI, phân tích xu hướng công nghệ và đề xuất các hướng nghiên cứu tiềm năng.

## Phân Tích Xu Hướng

### Từ Khóa Nổi Bật

| Từ Khóa | Tần Suất |
|---------|----------|
| models | 44 |
| agents | 42 |
| based | 36 |
| model | 33 |
| agent | 32 |
| learning | 32 |
| multi | 30 |
| framework | 28 |
| language | 28 |
| through | 28 |

### Cụm Từ Quan Trọng

| Cụm Từ | Tần Suất |
|---------|----------|
| large language | 15 |
| language models | 15 |
| multi agent | 14 |
| models llms | 8 |
| reinforcement learning | 7 |
| post training | 7 |
| real world | 6 |
| large scale | 6 |
| ai systems | 6 |
| artificial intelligence | 6 |

### Phân Bố Theo Chủ Đề

**AI Agents**: 26 papers (52.0%) ██████████

**LLM & Foundation Models**: 11 papers (22.0%) ████

**Other**: 7 papers (14.0%) ██

**RAG & Knowledge**: 4 papers (8.0%) █

**Automation & Tools**: 2 papers (4.0%) 

##  Đề Xuất Ý Tưởng Nghiên Cứu

### 1. Nghiên cứu ứng dụng large language trong các hệ thống models

**Mô tả:** Xu hướng mới nổi với 15 mentions

**Độ ưu tiên:** High

**Từ khóa liên quan:** large language, models

### 2. Phát triển framework language models cho agents

**Mô tả:** Xu hướng mới nổi với 15 mentions

**Độ ưu tiên:** High

**Từ khóa liên quan:** language models, agents

### 3. Đánh giá hiệu quả của multi agent trong bối cảnh based

**Mô tả:** Xu hướng mới nổi với 14 mentions

**Độ ưu tiên:** Medium

**Từ khóa liên quan:** multi agent, based

### 4. Tối ưu hóa models llms sử dụng kỹ thuật model

**Mô tả:** Xu hướng mới nổi với 8 mentions

**Độ ưu tiên:** Medium

**Từ khóa liên quan:** models llms, model

### 5. Kết hợp reinforcement learning và agent để cải thiện performance

**Mô tả:** Xu hướng mới nổi với 7 mentions

**Độ ưu tiên:** Medium

**Từ khóa liên quan:** reinforcement learning, agent

### 6. Khảo sát toàn diện về AI Agents trong Agentic AI

**Mô tả:** Có 26 papers gần đây về chủ đề này, cần tổng hợp hệ thống

**Độ ưu tiên:** High

**Từ khóa liên quan:** ai agents

### 7. Khảo sát toàn diện về LLM & Foundation Models trong Agentic AI

**Mô tả:** Có 11 papers gần đây về chủ đề này, cần tổng hợp hệ thống

**Độ ưu tiên:** Medium

**Từ khóa liên quan:** llm & foundation models

### 8. Khảo sát toàn diện về Other trong Agentic AI

**Mô tả:** Có 7 papers gần đây về chủ đề này, cần tổng hợp hệ thống

**Độ ưu tiên:** Medium

**Từ khóa liên quan:** other

##  Các Bài Báo Mới Nhất

### 1. Enterprise Deep Research: Steerable Multi-Agent Deep Research for Enterprise Analytics

**Tác giả:** Akshara Prabhakar, Roshan Ram, Zixiang Chen et al.

**Ngày xuất bản:** 2025-10-20

**Nguồn:** arxiv

**Tóm tắt:** As information grows exponentially, enterprises face increasing pressure to transform unstructured data into coherent, actionable insights. We present Enterprise Deep Research (EDR), a multi-agent system that integrates (1) a Master Planning Agent for adaptive query decomposition, (2) four specialized search agents (General, Academic, GitHub, LinkedIn), (3) an extensible MCP-based tool ecosystem supporting NL2SQL, file analysis, and enterprise workflows, (4) a Visualization Agent for data-driven insights, and (5) a reflection mechanism that detects knowledge gaps and updates research direction with optional human-in-the-loop steering guidance. On open-ended benchmarks including DeepResearch Bench and DeepConsult, EDR outperforms state-of-the-art agentic systems without any human steering.

**Link:** [http://arxiv.org/pdf/2510.17797v1](http://arxiv.org/pdf/2510.17797v1)

---

### 2. Executable Knowledge Graphs for Replicating AI Research

**Tác giả:** Yujie Luo, Zhuoyun Yu, Xuehai Wang et al.

**Ngày xuất bản:** 2025-10-20

**Nguồn:** arxiv

**Tóm tắt:** Replicating AI research is a crucial yet challenging task for large language model (LLM) agents. Existing approaches often struggle to generate executable code, primarily due to insufficient background knowledge and the limitations of retrieval-augmented generation (RAG) methods, which fail to capture latent technical details hidden in referenced papers. When integrated into three agent frameworks with two different LLMs, xKG shows substantial performance gains (10.9% with o3-mini) on PaperBench, demonstrating its effectiveness as a general and extensible solution for automated AI research replication.

**Link:** [http://arxiv.org/pdf/2510.17795v1](http://arxiv.org/pdf/2510.17795v1)

---

### 3. UltraCUA: A Foundation Model for Computer Use Agents with Hybrid Action

**Tác giả:** Yuhao Yang, Zhen Yang, Zi-Yi Dou et al.

**Ngày xuất bản:** 2025-10-20

**Nguồn:** arxiv

**Tóm tắt:** Multimodal agents for computer use rely exclusively on primitive actions (click, type, scroll) that require accurate visual grounding and lengthy execution chains, leading to cascading failures and performance bottlenecks. To achieve this, our approach comprises four key components: (1) an automated pipeline that scales programmatic tools from software documentation, open-source repositories, and code generation; (2) a synthetic data engine producing over 17,000 verifiable tasks spanning real-world computer-use scenarios; (3) a large-scale high-quality hybrid action trajectory collection with both low-level GUI actions and high-level programmatic tool calls; and (4) a two-stage training pipeline combining supervised fine-tuning with online reinforcement learning, enabling strategic alternation between low-level and high-level actions. We present UltraCUA, a foundation model that bridges this gap through hybrid action -- seamlessly integrating GUI primitives with high-level programmatic tool calls.

**Link:** [http://arxiv.org/pdf/2510.17790v1](http://arxiv.org/pdf/2510.17790v1)

---

### 4. Mapping Post-Training Forgetting in Language Models at Scale

**Tác giả:** Jackson Harmon, Andreas Hochlehnert, Matthias Bethge et al.

**Ngày xuất bản:** 2025-10-20

**Nguồn:** arxiv

**Tóm tắt:** Scaled post-training now drives many of the largest capability gains in language models (LMs), yet its effect on pretrained knowledge remains poorly understood. Our large-scale analysis shows that: (1) Domain-continual pretraining induces moderate forgetting with low-to-moderate backward transfer; (2) RL/SFT post-training applied to base models and Instruction tuning yields moderate-to-large backward transfer on math and logic with overall low-to-moderate forgetting; (3) Applying RL/SFT to instruction-tuned models is sensitive on data scale: at small scales, both forgetting and backward transfer are small; at larger scales, effects are mixed and warrant further study with better controls; (4) Model merging does not reliably mitigate forgetting. Overall, our framework offers a practical yardstick for mapping how post-training alters pretrained knowledge at scale -- enabling progress towards generally capable AI systems..

**Link:** [http://arxiv.org/pdf/2510.17776v1](http://arxiv.org/pdf/2510.17776v1)

---

### 5. Data-driven Communication and Control Design for Distributed Frequency Regulation with Black-box Inverters

**Tác giả:** Michael Nestor, Jiaxin Wang, Ning Zhang et al.

**Ngày xuất bản:** 2025-10-20

**Nguồn:** arxiv

**Tóm tắt:** The increasing penetration of inverter-based resources into the power grid, with often only black-box models available, challenges long-standing frequency control methods. To enable a trade off between communication network requirements and control performance, we present a framework to guide communication topology design for secondary frequency regulation. Following design of the inter-agent information exchange scheme, we design a controller that is structured according to the communication topology with a closed-loop stability guarantee.

**Link:** [http://arxiv.org/pdf/2510.17769v1](http://arxiv.org/pdf/2510.17769v1)

---

### 6. Phantom scalar field with arbitrary potential: accelerating scaling attractors

**Tác giả:** Sudip Halder, Supriya Pan, Paulo M. Sá et al.

**Ngày xuất bản:** 2025-10-20

**Nguồn:** arxiv

**Tóm tắt:** In this article, we investigate the dynamics of a phantom scalar field with an arbitrary potential, focusing on accelerating scaling solutions of cosmological relevance. Although there is a limitation to these scaling solutions $-$ specifically, the current stage of accelerated expansion is not preceded by a long enough matter-dominated era $-$ our results show that the existence of a direct coupling between phantom dark energy and dark matter yields great potential for addressing the cosmic coincidence problem.. We show that the uncoupled phantom cosmological model cannot accommodate any accelerated scaling solution, while such solutions do exist in the coupled scenario, for both constant and variable dissipation coefficients.

**Link:** [http://arxiv.org/pdf/2510.17765v1](http://arxiv.org/pdf/2510.17765v1)

---

### 7. Evaluating Medical LLMs by Levels of Autonomy: A Survey Moving from Benchmarks to Applications

**Tác giả:** Xiao Ye, Jacob Dineen, Zhaonan Li et al.

**Ngày xuất bản:** 2025-10-20

**Nguồn:** arxiv

**Tóm tắt:** Medical Large language models achieve strong scores on standard benchmarks; however, the transfer of those results to safe and reliable performance in clinical workflows remains a challenge. This survey reframes evaluation through a levels-of-autonomy lens (L0-L3), spanning informational tools, information transformation and aggregation, decision support, and supervised agents. This motivates a level-conditioned blueprint for selecting metrics, assembling evidence, and reporting claims, alongside directions that link evaluation to oversight.

**Link:** [http://arxiv.org/pdf/2510.17764v1](http://arxiv.org/pdf/2510.17764v1)

---

### 8. Human-AI Interactions: Cognitive, Behavioral, and Emotional Impacts

**Tác giả:** Celeste Riley, Omar Al-Refai, Yadira Colunga Reyes et al.

**Ngày xuất bản:** 2025-10-20

**Nguồn:** arxiv

**Tóm tắt:** As stories of human-AI interactions continue to be highlighted in the news and research platforms, the challenges are becoming more pronounced, including potential risks of overreliance, cognitive offloading, social and emotional manipulation, and the nuanced degradation of human agency and judgment. This paper aims to underscore the need for responsible and context-aware AI design, highlighting gaps for longitudinal research and grounded evaluation frameworks to balance benefits with emerging human-centric risks.. Observations seem to suggest that while AI can substantially enhance memory, creativity, and engagement, it also introduces risks such as diminished critical thinking, skill erosion, and increased anxiety.

**Link:** [http://arxiv.org/pdf/2510.17753v1](http://arxiv.org/pdf/2510.17753v1)

---

### 9. Rethinking Search: A Study of University Students' Perspectives on Using LLMs and Traditional Search Engines in Academic Problem Solving

**Tác giả:** Md. Faiyaz Abdullah Sayeedi, Md. Sadman Haque, Zobaer Ibn Razzaque et al.

**Ngày xuất bản:** 2025-10-20

**Nguồn:** arxiv

**Tóm tắt:** With the increasing integration of Artificial Intelligence (AI) in academic problem solving, university students frequently alternate between traditional search engines like Google and large language models (LLMs) for information retrieval. In response, we developed a prototype, a chatbot embedded within the search interface, that combines GPT's conversational capabilities with Google's reliability to enhance academic research and reduce cognitive load.. Qualitative insights revealed that students commonly switch between GPT and Google: using Google for credible, multi-source information and GPT for summarization, explanation, and drafting.

**Link:** [http://arxiv.org/pdf/2510.17726v1](http://arxiv.org/pdf/2510.17726v1)

---

### 10. MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues

**Tác giả:** Yaning Pan, Zekun Wang, Qianqian Xie et al.

**Ngày xuất bản:** 2025-10-20

**Nguồn:** arxiv

**Tóm tắt:** The recent development of Multimodal Large Language Models (MLLMs) has significantly advanced AI's ability to understand visual modalities. With MT-Video-Bench, we extensively evaluate various state-of-the-art open-source and closed-source MLLMs, revealing their significant performance discrepancies and limitations in handling multi-turn video dialogues. Specifically, our MT-Video-Bench mainly assesses six core competencies that focus on perceptivity and interactivity, encompassing 987 meticulously curated multi-turn dialogues from diverse domains.

**Link:** [http://arxiv.org/pdf/2510.17722v1](http://arxiv.org/pdf/2510.17722v1)

---

### 11. Discrimination, intelligence artificielle et decisions algorithmiques

**Tác giả:** Frederik Zuiderveen Borgesius

**Ngày xuất bản:** 2025-10-20

**Nguồn:** arxiv

**Tóm tắt:** Artificial intelligence (AI) has a huge impact on our personal lives and also on our democratic society as a whole. Frederik Zuiderveen Borgesius for the Anti-discrimination Department of the Council of Europe, elaborates on the risks of discrimination caused by algorithmic decision-making and other types of artificial intelligence (AI).. While AI offers vast opportunities for the benefit of people, its potential to embed and perpetuate bias and discrimination remains one of the most pressing challenges deriving from its increasing use.

**Link:** [http://arxiv.org/pdf/2510.17711v1](http://arxiv.org/pdf/2510.17711v1)

---

### 12. Towards Mining Effective Pedagogical Strategies from Learner-LLM Educational Dialogues

**Tác giả:** Liqun He, Manolis Mavrikis, Mutlu Cukurova

**Ngày xuất bản:** 2025-10-20

**Nguồn:** arxiv

**Tóm tắt:** Dialogue plays a crucial role in educational settings, yet existing evaluation methods for educational applications of large language models (LLMs) primarily focus on technical performance or learning outcomes, often neglecting attention to learner-LLM interactions. To narrow this gap, this AIED Doctoral Consortium paper presents an ongoing study employing a dialogue analysis approach to identify effective pedagogical strategies from learner-LLM dialogues. The work underscores the need to evaluate LLM-based educational applications by focusing on dialogue dynamics and pedagogical strategies..

**Link:** [http://arxiv.org/pdf/2510.17698v1](http://arxiv.org/pdf/2510.17698v1)

---

### 13. A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning

**Tác giả:** Anjie Liu, Jianhong Wang, Samuel Kaski et al.

**Ngày xuất bản:** 2025-10-20

**Nguồn:** arxiv

**Tóm tắt:** Steering cooperative multi-agent reinforcement learning (MARL) towards desired outcomes is challenging, particularly when the global guidance from a human on the whole multi-agent system is impractical in a large-scale MARL. Since MAIDs can be regarded as a special class of causal diagrams, a composite desired outcome that integrates the primary task goal and an additional desired outcome can be achieved by maximizing the corresponding causal effect through the PSI. Then, we design a new interaction paradigm based on MAIDs, referred to as targeted intervention that is applied to only a single targeted agent, so the problem of global guidance can be mitigated.

**Link:** [http://arxiv.org/pdf/2510.17697v1](http://arxiv.org/pdf/2510.17697v1)

---

### 14. Semantic Joint Source Channel Coding for Distributed Subsurface Imaging in Multi-Agent Systems

**Tác giả:** Maximilian H. V. Tillmann, Ban-Sok Shin, Dmitriy Shutin et al.

**Ngày xuất bản:** 2025-10-20

**Nguồn:** arxiv

**Tóm tắt:** Multi-agent systems (MAS) are a promising solution for autonomous exploration tasks in hazardous or remote environments, such as planetary surveys. Specifically, we investigate the application of semantic joint source-channel coding (JSCC) with over-the-air computation (AirComp) for distributed function computation for the application of cooperative subsurface imaging using the adapt-then-combine full waveform inversion (ATC-FWI) algorithm. This work presents a novel framework that tightly integrates semantic communication into the MAS exploration process, adapting communication strategies to the exploration methodology to improve overall task performance.

**Link:** [http://arxiv.org/pdf/2510.17695v1](http://arxiv.org/pdf/2510.17695v1)

---

### 15. A Mimamsa Inspired Framework For Instruction Sequencing In AI Agents

**Tác giả:** Bama Srinivasan

**Ngày xuất bản:** 2025-10-20

**Nguồn:** arxiv

**Tóm tắt:** This paper presents a formal framework for sequencing instructions in AI agents, inspired by the Indian philosophical system of Mimamsa. The framework formalizes sequencing mechanisms through action object pairs in three distinct ways: direct assertion (Srutikrama) for temporal precedence, purpose driven sequencing (Arthakrama) for functional dependencies, and iterative procedures (Pravrittikrama) for distinguishing between parallel and sequential execution in repetitive tasks. This formal verification enables reliable instruction sequencing, impacting AI applications across areas like task planning and robotics by addressing temporal reasoning and dependency modeling..

**Link:** [http://arxiv.org/pdf/2510.17691v1](http://arxiv.org/pdf/2510.17691v1)

---

### 16. 4DSegStreamer: Streaming 4D Panoptic Segmentation via Dual Threads

**Tác giả:** Ling Liu, Jun Tian, Li Yi

**Ngày xuất bản:** 2025-10-20

**Nguồn:** arxiv

**Tóm tắt:** 4D panoptic segmentation in a streaming setting is critical for highly dynamic environments, such as evacuating dense crowds and autonomous driving in complex scenarios, where real-time, fine-grained perception within a constrained time budget is essential. The inference thread ensures timely prediction for incoming frames by aligning with the latest memory and compensating for ego-motion and dynamic object movements. Comprehensive experiments demonstrate the effectiveness of our approach, particularly in accurately predicting dynamic objects in complex scenes..

**Link:** [http://arxiv.org/pdf/2510.17664v1](http://arxiv.org/pdf/2510.17664v1)

---

### 17. Frugal Federated Learning for Violence Detection: A Comparison of LoRA-Tuned VLMs and Personalized CNNs

**Tác giả:** Sébastien Thuau, Siba Haidar, Ayush Bajracharya et al.

**Ngày xuất bản:** 2025-10-20

**Nguồn:** arxiv

**Tóm tắt:** We examine frugal federated learning approaches to violence detection by comparing two complementary strategies: (i) zero-shot and federated fine-tuning of vision-language models (VLMs), and (ii) personalized training of a compact 3D convolutional neural network (CNN3D). To our knowledge, this is the first comparative study of LoRA-tuned vision-language models and personalized CNNs for federated violence detection, with an emphasis on energy efficiency and environmental metrics. The resulting framework offers a reproducible baseline for responsible, resource-aware AI in video surveillance, with extensions toward real-time, multimodal, and lifecycle-aware systems..

**Link:** [http://arxiv.org/pdf/2510.17651v1](http://arxiv.org/pdf/2510.17651v1)

---

### 18. CaMiT: A Time-Aware Car Model Dataset for Classification and Generation

**Tác giả:** Frédéric LIN, Biruk Abere Ambaw, Adrian Popescu et al.

**Ngày xuất bản:** 2025-10-20

**Nguồn:** arxiv

**Tóm tắt:** AI systems must adapt to evolving visual environments, especially in domains where object appearances change over time. Static pretraining on in-domain data achieves competitive performance with large-scale generalist models while being more resource-efficient, yet accuracy declines when models are tested across years. We evaluate two strategies: time-incremental pretraining, which updates the backbone, and time-incremental classifier learning, which updates only the final layer, both improving temporal robustness.

**Link:** [http://arxiv.org/pdf/2510.17626v1](http://arxiv.org/pdf/2510.17626v1)

---

### 19. ImaGGen: Zero-Shot Generation of Co-Speech Semantic Gestures Grounded in Language and Image Input

**Tác giả:** Hendric Voss, Stefan Kopp

**Ngày xuất bản:** 2025-10-20

**Nguồn:** arxiv

**Tóm tắt:** Human communication combines speech with expressive nonverbal cues such as hand gestures that serve manifold communicative functions. While challenges remain in representing complex shapes, our results highlight the importance of context-aware semantic gestures for creating expressive and collaborative virtual agents or avatars, marking a substantial step forward towards efficient and robust, embodied human-agent interaction. In scenarios where speech alone was ambiguous, gestures generated by our system significantly improved participants' ability to identify object properties, confirming their interpretability and communicative value.

**Link:** [http://arxiv.org/pdf/2510.17617v1](http://arxiv.org/pdf/2510.17617v1)

---

### 20. ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling

**Tác giả:** Shuyuan Zhang, Chenhan Jiang, Zuoou Li et al.

**Ngày xuất bản:** 2025-10-20

**Nguồn:** arxiv

**Tóm tắt:** 3D generation from natural language offers significant potential to reduce expert manual modeling efforts and enhance accessibility to 3D assets. At its core, we propose a Graph-based Procedural Shape (GPS) representation that decomposes complex natural language into a structured graph of sub-tasks, thereby facilitating accurate LLM comprehension and interpretation of spatial relationships and semantic shape details. Qualitative and quantitative experiments demonstrate ShapeCraft's superior performance in generating geometrically accurate and semantically rich 3D assets compared to existing LLM-based agents.

**Link:** [http://arxiv.org/pdf/2510.17603v1](http://arxiv.org/pdf/2510.17603v1)

---

## Ghi Chú

Báo cáo này được tạo tự động bởi Agentic AI Research System.
Dữ liệu được thu thập từ ArXiv và Semantic Scholar.

